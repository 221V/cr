<html>
<head>
    <meta charset="utf-8" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="" />
    <meta name="author" content="Maxim Sokhatsky" />
    <title>CR</title>
    <link rel="stylesheet" href="http://5ht.github.io/5HT.css" />
</head>
<body>
<div class=app>

<div align=right>FROM: 5HT<br>
                   TO: PUB<br>
                 DATE: 15 MAR 2015</div>

<h2>Chain Replication Database</h2>

<div class=message>

<p>In banking system demands are very tight. Database
should be at least tripled, stand-by nodes should pick up
master reads from failover node, writes should be
accepted on a reasonble quorum, failover must be followed by recovery, database
should be able to scale even with the RAM/DISC limitations.</p>

<p>No data should be treated as written otherwise that commited to all replicas.
All this circumstances leads us to chain replication protocol as a simple and natural
feedback to this challenge.</p>

<p>Different replication techniques exists to satisfy replication demands.
Master-slave replication is most widely known type of replication
used before in such products like GFS, HDFS, mongodb, etc. Quorum Intersection
is another technique used in databases like Cassandra or Amazon Dynamo.
They mostly provide a consistent distributed repository
for event tables or for file storage. In banking industry
we synchronize account balances and need simple and managable
protocol for storage consistency issuing high demand on system integrity.
</p>

<p>There are several classes of error usually implied when dealing with failure detection.
The most weak class is fail-stop events, when the outage is normal or predictable.
The second class is crash-failures, the ubnormal terminations and outages. The most strong
type of failures are byzantine failures resistant to bit-flips,
hacked parties or any types of compromising the transaction objects.
For banking applications the byzantine fault tolerance is desired,
despite it affects the latency.</p>

<h3>Features</h3>

<p>
<ul>
<li>CP database</li>
<li>2N+1 nodes tolerates N failures</li>
<li>Consistent hashing DHT</li>
<li>RAFT for managing server configurations timeline</li>
<li>HMAC signing for Byzantine capabilities</li>
<li>Various database backends: <b>mnesia</b>, <b>riak</b>, <b>redis</b>, <b>fs</b>, <b>sql</b></li>
<li>High-performance non-blocking TCP acceptor</li>
<li>Separate endpoints for HEART, CLIENT and SERVER protocols</li>
<li>Pure, clean and understandable codebase</li></ul></p>

<h3>Basic protocol</h3>

<p><div class=note style="background-color:#FAFAFA;"><p><b>Command</b>
<code>
</code><p></div>
<div class=note>
<p>Command is the atomic event that can be performed
in single process context at a single machine.</p></div></P>

<p>CR provides extensible set of possible commands:</p>

<p>
<ul>
<li>PUT the object to database</li>
<li>LINK the object to some doubly-linked list</li>
<li>REMOVE the object from the list and database</li>
</ul></p>

<p>This set of commands refers to KVS the database framework for
storing the doubly linked lists (it can be called chains/feeds/sequences)
using the two basic record types: <b>#container</b>, who store the top of a chain along
with chain aggregation counters; and <b>#iterator</b>, who provides next and prev
fields for traversal.</p>

<div class=note style="background-color:#FAFAFA;"><p><b>Distributed Transaction</b>
<code>
</code><p></div>
<div class=note>
<p>All replicas are sequenced into the chains. Transaction is a
command performing forward over the ordered chain of replicas. This chain
is called configuration. All writes come to the chain's head,
all reads come to chain's tail.</p></div>

<p><center>Picture 1. Chain<br><br><img src="images/replicas.svg" height=200></center></p>

<p><div class=note style="background-color:#FAFAFA;"><p><b>Replication Log</b>
<code>
</code><p></div>
<div class=note>
<p>During transaction, the command is saved in replication
log on each replica of the transaction. This log is append-only
disk structure and is also called this history of replica's operations.</p></div></p>

<p>The replication log is also uses KVS as underlying storage.
As a replication log container it uses <b>#log</b> type and command is stored
as <b>#operation</b> record. Each replica has its own log.</p>

<p><center>Picture 2. Log<br><br><img src="images/log.svg" height=400></center></p>

<h3>Failures</h3>

<p><div class=note style="background-color:#FAFAFA;"><p><b>Configuration Tracking</b>
<code>
</code><p></div>
<div class=note>
<p>The configuration is a dynamic property of transaction.
During transaction it may change due to byzantine failures,
leading us to reconfigure the replicas in a chain. The another consistent
system is needed to track the dynamic configurations.</p></div></P>

<p>To make the shard highly available, we use replication
and dynamically change the configuration of replicas
in order to deal with crash failures and unresponsiveness.
Each machine in a cluster has single append-only configuration
log which is not based on KVS due to latency requirements.
Configuration log is a binary file written by RAFT protocol commands.
There is only two commands which could be performed over the configuration log:</p>

<p>
<ul>
<li>ADD replica to configuration</li>
<li>DELETE replica from configuration</li>
</ul></p>

<h3>Safety</h3>

<div class=note style="background-color:#FAFAFA;"><p><b>Stable Log</b>
<code>
</code><p>
</div>
<div class=note>
<p>During split-brains some operation could be accepted for writing,
as deposition, account or client creation, etc having N+1 live replicas among 2*N+1 nodes.
Such operations as withdraw or balance check should be performed only on quorum island.
</p></div>

<p><center>Picture 3. Stable Configurations<br><br><img src="images/merging.svg" height=300></center></p>

<h3>Liveness</h3>

<h3>OTP protocol</h3>

<p>Some types are embedded in L core to resolve main tasks during
type inference, type unification and patterm maching compilation.
L has following basic types which are used by infer/unify/match core.
These types are also shared with Type Inspector.</p>

<div class=note style="background-color:#fafafa;"><p>INTERCONNECT<ul>
    <li>transaction</li>
    <li>get</li>
    <li>sync</li>
    </ul></p></div>
<div class=note><p>PING<ul>
    <li>ping</li>
    <li>join</li>
    <li>leave</li>
</ul></p></div>

<h3>Implementation</h3>

<p>The chain replication protolcol is implementes as <b>Erlang/OTP</b> application <b>cr</b>
that could be embeded in any toplevel application. We use one supervision
tree and <b>gen_server</b> per one TCP endpoint along with separate
<b>vnode_sup</b> supervision for VNODE transactional contexts per hashring vnode.</p>

<p><center>Picture 4. Supervision<br><br><img src="images/sup.png" height=400></center></p>

<br>

<div class=note>
<pre>
> [{T,Pid}||{T,Pid,_,_}<-supervisor:which_children(cr_sup)].

[{vnode_sup,<0.52.0>},
 {client_sup,<0.51.0>},
 {client,<0.50.0>},
 {ping_sup,<0.289.0>},
 {ping,<0.48.0>},
 {interconnect_sup,<0.47.0>},
 {interconnect,<0.46.0>}]
</pre></div>

<h3>Consistent Hash Ring</h3>

<p>Bulding a consistent hash ring is a key feature
that opens a door to the distributed system.
CR is using only five functions to model the DHT ring.</p>

<div class=note>
<pre>
> [{I,P}||{{I,_},P,_,_} <- supervisor:which_children(vnode_sup)].

[{1461501637330902918203684832716283019655932542960,<0.53.0>},
 {1424964096397630345248592711898375944164534229386,<0.54.0>},
 {1388426555464357772293500591080468868673135915812,<0.55.0>},
 {1351889014531085199338408470262561793181737602238,<0.56.0>},
 {1315351473597812626383316349444654717690339288664,<0.57.0>},
 {1278813932664540053428224228626747642198940975090,<0.58.0>},
 {1242276391731267480473132107808840566707542661516,<0.59.0>},
 {1205738850797994907518039986990933491216144347942,<0.60.0>}]
</pre></div>

<h3>Literature</h3>

&nbsp;[1]. Hussam Abu-Libdeh, Robbert van Renesse, Ymir Vigfusson.<br>
<a href="http://www.ymsir.com/papers/sharding-socc.pdf">
&nbsp;&nbsp;&nbsp;&nbsp; Leveraging Sharding in the Design of Scalable Replication Protocols</a><br><br>

[2]. Robbert van Renesse, Chi Ho, Nicolas Schiper.<br>
<a href="http://www.cs.cornell.edu/home/rvr/newpapers/opodis2012.pdf">
&nbsp;&nbsp;&nbsp;&nbsp; Byzantine Chain Replication</a><br><br>

[3]. Robbert van Renesse, Nicolas Schiper.<br>
<a href="http://www.cs.cornell.edu/home/rvr/papers/osdi04.pdf">
&nbsp;&nbsp;&nbsp;&nbsp; Chain Replication for
Supporting High Throughput and Availability</a>

<h3>Credits</h3>

<p>
<ul>
<li>Maxim Sokhatsky</li>
<li>Vladimir Kirillov</li>
<li>Sergey Klimenko</li>
<li>Valery Maleshkin</li>
<li>Victor Sovietov</li>
</ul></p>

<br><br>
<center> 2015 &copy; Synrc Research Center, s.r.o.</center>

</div>
</div>
</body>
</html>
